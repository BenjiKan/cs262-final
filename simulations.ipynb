{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic matrices and server popularity distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_traffic_matrix(sending, receiving):\n",
    "    # normalize vectors\n",
    "    sending = sending / np.linalg.norm(sending)\n",
    "    receiving = receiving / np.linalg.norm(receiving)\n",
    "\n",
    "    # sending and receiving are vectors of length n, reshape them to be nx1 and 1xn\n",
    "    sending = np.reshape(sending, (len(sending), 1))\n",
    "    receiving = np.reshape(receiving, (1, len(receiving)))\n",
    "    \n",
    "    # multiply the two vectors to get an nxn matrix \n",
    "    matrix = sending @ receiving\n",
    "    np.fill_diagonal(matrix, 0)\n",
    "    \n",
    "    return matrix / np.sum(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different distributions for server popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unif(n):\n",
    "    # generate a uniform vector of length n\n",
    "    return np.ones(n) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random(n):\n",
    "    # generate a random vector of length n\n",
    "    popularities = np.random.rand(n)\n",
    "    return popularities / np.linalg.norm(popularities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussian(n, std=0.1):\n",
    "    # generate a uniform vector of length n, with some Gaussian noise added. default std is 0.1\n",
    "    popularities = np.random.rand(n) + np.random.normal(0, std, n)\n",
    "    return popularities / np.linalg.norm(popularities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate popularities according to Pareto dist\n",
    "\n",
    "def generate_zipf(n, repeat=1):\n",
    "    \"\"\"Returns nodes' popularities according to Zipf dist\n",
    "    ARGS:\n",
    "        n: number of nodes\n",
    "        repeat: number of nodes with 1/i popularity\n",
    "        \n",
    "    OUTPUTS:\n",
    "        popularities: list of popularity for each node, following an approximate Zipf distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    popularities = np.array([1/np.ceil(i/repeat) for i in range(1,n+1)]) # repeated Zipf function\n",
    "    return popularities / np.linalg.norm(popularities) # normalize\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jellyfish(num_switches, other_switches_per_switch, servers_per_switch):\n",
    "    # indices 0 to num_switches - 1 are switches\n",
    "    G = nx.random_regular_graph(d=other_switches_per_switch, n=num_switches)\n",
    "    \n",
    "    # indices num_switches to num_switches + num_switches * servers_per_switch - 1 are servers\n",
    "    for i in range(num_switches):\n",
    "        for j in range(servers_per_switch):\n",
    "            server_index = num_switches + i * servers_per_switch + j \n",
    "            G.add_node(server_index)\n",
    "            G.add_edge(i, server_index)\n",
    "            # servers.append(server_index)\n",
    "    \n",
    "    # list of all servers\n",
    "    servers = range(num_switches, num_switches + num_switches * servers_per_switch)\n",
    "    \n",
    "    return G, servers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(50, 250)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "G, servers = create_jellyfish(num_switches=50, other_switches_per_switch=4, servers_per_switch=4)\n",
    "# G, servers = create_jellyfish(num_switches=10, other_switches_per_switch=3, servers_per_switch=2)\n",
    "print(servers)\n",
    "print(nx.shortest_path_length(G, source=30, target=55))\n",
    "# pos = nx.shell_layout(G)\n",
    "# nx.draw(G, pos)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def switch_weight(source, target, edge_attr):\n",
    "    if source in servers or target in servers:\n",
    "        return 1\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "def distance_weight(source, target, edge_attr):\n",
    "    if source in servers or target in servers:\n",
    "        return 1\n",
    "    else:\n",
    "        return target-source\n",
    "nx.shortest_path_length(G, source=130, target=155, weight=switch_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_path_length(G, servers, edge_weight=None):\n",
    "    num_servers = len(servers)\n",
    "    servers = np.random.permutation(servers) # randomly permute servers\n",
    "\n",
    "    shortest_path_lengths = np.zeros((num_servers, num_servers))\n",
    "    for i in range(num_servers):\n",
    "        for j in range(num_servers):\n",
    "            shortest_path_lengths[i, j] = nx.shortest_path_length(G, source=servers[i], target=servers[j], weight=edge_weight)\n",
    "\n",
    "    unif_traffic_matrix = generate_traffic_matrix(generate_unif(num_servers), generate_unif(num_servers)) \n",
    "    print(\"Uniform traffic\", np.sum(np.multiply(shortest_path_lengths, unif_traffic_matrix)))\n",
    "    random_traffic_matrix = generate_traffic_matrix(generate_random(num_servers), generate_random(num_servers))\n",
    "    print(\"Random traffic\", np.sum(np.multiply(shortest_path_lengths, random_traffic_matrix)))\n",
    "    gaussian_traffic_matrix = generate_traffic_matrix(generate_gaussian(num_servers, std=0.25), generate_gaussian(num_servers, std=0.25))\n",
    "    print(\"Gaussian traffic\", np.sum(np.multiply(shortest_path_lengths, gaussian_traffic_matrix)))\n",
    "    zipf_traffic_matrix = generate_traffic_matrix(generate_zipf(num_servers, repeat=5), generate_zipf(num_servers, repeat=5))\n",
    "    print(\"Zipf traffic\", np.sum(np.multiply(shortest_path_lengths, zipf_traffic_matrix)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform traffic 16.552763819095482\n",
      "Random traffic 16.561651596693206\n",
      "Gaussian traffic 16.58101197368703\n",
      "Zipf traffic 16.593367065093634\n"
     ]
    }
   ],
   "source": [
    "calculate_weighted_path_length(G, servers, edge_weight=switch_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
